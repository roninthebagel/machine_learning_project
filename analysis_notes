## --- defining the model with tidymodel --- ##


Why is linear regression an appropriate starting point for this biological question?

- a straightforward approach to quantifying relationships between variables

###

What assumptions are we making about the relationship between methylation levels and age?

- assuming changes in methylation at specific CpG sites correlate linearly with age

###

What other preprocessing steps might be helpful when working with methylation data? Would scaling (standardising) the predictors also be beneficial? Why or why not?

- removing highly correlated CpG sites to reduce redundancy
- scaling (standardising) methylation values if they have very different variances 
- transforming skewed methylation distributions
- imputing missing values if some CpG sites have gaps

###

What is actually happening when we “fit” a linear regression model to methylation data? What are we trying to do?

- when fitting an ordinary regression model we attempt to find the coefficient values through the process of ordinary least squares

###

Which CpG sites appear most important for predicting age? Are there any that don’t seem significantly associated with age?

- CpG 1 TET2, CpG 3 TET2, and ASPA 1 all present negative coefficients (estimates), suggesting these are sites where methylation decreases with age. All the other sites show positive coefficients, which is where methylation increases with age. 
- Using our assumption, where we assumed "changes in methylation at specific CpG sites correlate linearly with age", we woudld expect methylation to increase with age. So we can state that the sites presenting positive coefficients show this trend, and so are important for predicting age. 

###

What would be an acceptable error margin for age prediction in your biological context? How might this compare to other methods of age determination in bats?

- RMSE tells us the typical error in our age predictions in years, so we can use that value as an error margin for age prediction. 
- 

###

What assumptions does linear regression make, and do our model diagnostics suggest these assumptions are met? Look particularly at: - Linearity (do residuals show patterns?) - Homoscedasticity (is residual variance constant across predicted values?) - Normality of residuals - Influential outliers

- linear regressions assume that the relationship between the predictor variables and the outcome are linear.
- in the linearity graph, the reference line is not completely flat and horizontal, suggesting that we may need to transform the data to gain a better fit.

###

Based on our diagnostics, what specific improvements might help our model? What biological mechanisms might explain non-linear relationships between methylation and age?

- transforming (i.e. log-transformating) our data will help to gain a better fit.
- there may be other predictors and environmental factors which may alter the relationship between methylation and age


## --- training and testing sets --- ##


Why is it important to evaluate our model on a separate test set?

- models have two competing goals:
  - accurately capturing patterns in your data (1) while ignoring random noise (2)
- without a separate test set, you can’t tell if your model is actually learning generalisable patterns or simply memorizing the training examples (overfitting)

###

What might happen if we only evaluated performance on our training data?

- when you evaluate performance on the same data used for training:
  - performance metrics will be artificially inflated
  - you’ll have no reliable way to predict how your model will perform on new data
  - you might select an overly complex model that fits noise rather than signal

###

How does the performance on the test set compare to the training set? If there’s a large difference, what might that indicate?

- the two sets are quite similar, particularly as the same three CpG sites are negative in both sets (and the rest are positive)

###

What advantages does cross-validation offer over a single train/test split? How consistent are the results across folds?

- cross-validation uses multiple train/test splits. 
- in k-fold cross-validation:
  - your dataset is divided into k equally sized segments (or “folds”)
  - the model is trained and tested k times
  - each time, a different fold serves as the test set while the remaining k-1 folds form the training set
  - performance metrics are averaged across all k iterations

###

How does the number of folds affect the stability and value of the performance metrics? What tradeoffs are involved in choosing a higher or lower number of folds?

- the mean performance in rmse and rsq can vary depending on the number of folds. rmse tends to decrease in mean performance as the number of folds increases, whilst the rsq increases with the mean performance.

###

What improvements would make this model more useful for real-world biological applications? What additional data would strengthen the model’s reliability?

- our methylation-based age prediction model could be valuable for:
  - non-invasive age determination in wild bat populations 
  - studying how environmental factors affect biological aging rates 
  - comparing aging patterns across different bat species 
  - investigating the health effects of factors like habitat fragmentation


## --- alternative models --- ##


With methylation data, why might overfitting be a particular concern? Consider the typical dimensionality of methylation datasets.

- overfitting models may lead to incorrect analysis of data, or the missing of certain trends. 

###

When would you prefer Ridge over Lasso for methylation data analysis? Consider the biological meaning of correlated CpG sites.

- ridge regression is useful when multiple CpG sites provide partially redundant information about age (which is common in methylation data).
- rather than selecting just one site from a correlated group (as lasso 
might), ridge keeps all sites but reduces their individual influence.


## --- K-nearest neighbours (KNN) regression --- ##


What happens as K increases? How might this affect our age predictions?

- KNN is a non-parametric approach that predicts a sample’s age based on the average age of its K nearest neighbors in methylation pattern space.
- As K increases, the sample's age is predicted to increase too.

###

Based on these visualizations (plot lists), which model appears to perform best? Are there age ranges where certain models excel or struggle?

- the KNN model has data which is least fit to the model (points are furthest from the intercept line)
- non-fit models can lead to inaccuracies in further data analyses models


## --- proper model training with cross-validation --- ##

How does proper tuning affect model performance? Why is this cross-validation approach better than just trying different values on the whole dataset?

- hyperparameters control how a machine-learning model learns from data.
- correctly tuning hyperparameters can improve a model's performance. Poor settings may cause:
  - underfitting: the model is too simple to capture the underlying patterns.
  - overfitting: the model is too complex and captures noise rather than useful patterns, leading to poor generalization.
  - slow convergence: poorly tuned models, such as those with too small a learning rate, can take excessively long to converge or may not converge at all.


## --- summary of model comparison --- ##

Which model would you choose for your bat aging research, and why? Consider both statistical performance and biological interpretability.

- each model has it's own strengths and weaknesses, so there is no right or wrong answer here
- i would probably use the ridge model, as the model handles correlated CpG sites well and reduces overfitting.
- ridge models would, however, require tuning beforehand (which can quickly and easily be applied).
- this model also retains all features (no clear feature selection), so would be unable to  improve the model's accuracy scores or to boost its performance on very high-dimensional datasets.
- multiple analyses could be selected to compare results and account for these weaknesses.
